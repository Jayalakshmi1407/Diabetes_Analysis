# Comprehensive Pima Indian Diabetes Dataset Analysis
# Author: Streamlit Expert Data Analyst
# Description: Complete exploratory and inferential statistical analysis

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from scipy import stats
from scipy.stats import chi2_contingency, mannwhitneyu, f_oneway
import statsmodels.api as sm
from statsmodels.stats.diagnostic import het_breuschpagan
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, roc_auc_score, roc_curve
from sklearn.preprocessing import StandardScaler
from streamlit_option_menu import option_menu
import warnings
warnings.filterwarnings('ignore')

# ---------------- CONFIG ----------------
st.set_page_config(
    page_title="Pima Indian Diabetes Analysis", 
    page_icon="ü©∫", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS styling
st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .kpi-card {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin: 0.5rem;
    }
    .metric-card {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #007bff;
        margin: 0.5rem 0;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 2px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        padding-left: 20px;
        padding-right: 20px;
    }
    </style>
""", unsafe_allow_html=True)

# ---------------- HELPER FUNCTIONS ----------------
def plot_kpi(title, value, delta=None):
    """Create KPI card display"""
    if delta:
        st.metric(label=title, value=value, delta=delta)
    else:
        st.metric(label=title, value=value)

def create_age_groups(age):
    """Categorize age into groups"""
    if age < 30:
        return "<30"
    elif age < 40:
        return "30-39"
    elif age < 50:
        return "40-49"
    else:
        return "50+"

def create_bmi_categories(bmi):
    """Categorize BMI into standard categories"""
    if bmi < 18.5:
        return "Underweight"
    elif bmi < 25:
        return "Normal"
    elif bmi < 30:
        return "Overweight"
    else:
        return "Obese"

def create_pregnancy_groups(pregnancies):
    """Categorize pregnancies into groups"""
    if pregnancies == 0:
        return "0"
    elif pregnancies <= 2:
        return "1-2"
    elif pregnancies <= 4:
        return "3-4"
    else:
        return "5+"

def detect_outliers_zscore(data, threshold=3):
    """Detect outliers using Z-score method"""
    z_scores = np.abs(stats.zscore(data))
    return z_scores > threshold

def hosmer_lemeshow_test(y_true, y_prob, g=10):
    """Perform Hosmer-Lemeshow goodness of fit test"""
    df_hl = pd.DataFrame({'y_true': y_true, 'y_prob': y_prob})
    df_hl['decile'] = pd.qcut(df_hl['y_prob'], g, duplicates='drop')
    
    hl_table = df_hl.groupby('decile').agg({
        'y_true': ['count', 'sum'],
        'y_prob': 'mean'
    }).round(4)
    
    observed_pos = hl_table[('y_true', 'sum')].values
    observed_neg = hl_table[('y_true', 'count')].values - observed_pos
    expected_pos = hl_table[('y_true', 'count')].values * hl_table[('y_prob', 'mean')].values
    expected_neg = hl_table[('y_true', 'count')].values - expected_pos
    
    hl_stat = np.sum((observed_pos - expected_pos)**2 / expected_pos + 
                     (observed_neg - expected_neg)**2 / expected_neg)
    p_value = 1 - stats.chi2.cdf(hl_stat, g-2)
    
    return hl_stat, p_value

# ---------------- LOAD DATA ----------------
@st.cache_data
def load_data():
    """Load and preprocess the diabetes dataset"""
    df = pd.read_csv("diabetes.csv")
    
    # Create derived variables
    df['AgeGroup'] = df['Age'].apply(create_age_groups)
    df['BMICategory'] = df['BMI'].apply(create_bmi_categories)
    df['PregnancyGroup'] = df['Pregnancies'].apply(create_pregnancy_groups)
    
    return df

df = load_data()

# ---------------- NAVIGATION ----------------
with st.sidebar:
    selected = option_menu(
        menu_title="Navigation",
        options=["Introduction", "Exploration", "Inferential Analysis", "Models", "Conclusions"],
        icons=["house", "search", "graph-up", "cpu", "check-circle"],
        menu_icon="cast",
        default_index=0,
        styles={
            "container": {"padding": "0!important", "background-color": "#ffffff"},
            "icon": {"color": "#ff6b35", "font-size": "18px"},
            "nav-link": {
                "font-size": "16px", 
                "text-align": "left", 
                "margin": "0px", 
                "padding": "10px 15px",
                "color": "#262730",
                "background-color": "#f0f2f6",
                "border-radius": "5px",
                "margin-bottom": "5px",
                "--hover-color": "#e1e5f2"
            },
            "nav-link-selected": {
                "background-color": "#1f77b4",
                "color": "white",
                "font-weight": "bold"
            },
        }
    )

# ---------------- PAGE CONTENT ----------------
if selected == "Introduction":
    st.markdown('<h1 class="main-header">ü©∫ Pima Indian Diabetes Dataset Analysis</h1>', unsafe_allow_html=True)
    
    # Introduction to diabetes
    st.markdown("""
    ## üåç Diabetes: A Global Health Concern
    
    Diabetes mellitus is a chronic metabolic disorder characterized by elevated blood glucose levels. 
    It affects over 400 million people worldwide and is a leading cause of cardiovascular disease, 
    blindness, kidney failure, and lower limb amputation.
    
    ### üìä Dataset Overview
    
    The **Pima Indian Diabetes Dataset** contains medical diagnostic measurements for 768 Pima Indian women, 
    aged 21 years and older. This population has a high incidence of diabetes, making it valuable for 
    predictive modeling research.
    """)
    
    # Dataset variables explanation
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        ### üìã Dataset Variables
        
        - **Pregnancies**: Number of times pregnant
        - **Glucose**: Plasma glucose concentration (mg/dL)
        - **BloodPressure**: Diastolic blood pressure (mm Hg)
        - **SkinThickness**: Triceps skin fold thickness (mm)
        - **Insulin**: 2-Hour serum insulin (mu U/ml)
        """)
    
    with col2:
        st.markdown("""
        ### üìã Additional Variables
        
        - **BMI**: Body mass index (weight in kg/(height in m)¬≤)
        - **DiabetesPedigreeFunction**: Diabetes pedigree function
        - **Age**: Age in years
        - **Outcome**: Class variable (0: No diabetes, 1: Diabetes)
        """)
    
    # Quick dataset preview
    st.markdown("### üëÄ Dataset Preview")
    st.dataframe(df.head(10), use_container_width=True)

elif selected == "Exploration":
    st.header("üîç Data Exploration & Descriptive Statistics")
    
    # Key metrics
    st.markdown("### üìä Key Dataset Metrics")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        plot_kpi("Total Individuals", f"{len(df):,}")
    with col2:
        diabetes_rate = df['Outcome'].mean() * 100
        plot_kpi("Diabetes Rate", f"{diabetes_rate:.1f}%")
    with col3:
        plot_kpi("Features", df.shape[1])
    with col4:
        plot_kpi("Age Range", f"{df['Age'].min()}-{df['Age'].max()}")
    
    # Descriptive statistics
    st.markdown("### üìà Descriptive Statistics")
    
    # Select variables for detailed analysis
    variables = ['Age', 'BMI', 'Glucose', 'BloodPressure', 'Pregnancies']
    
    # Create tabs for different analyses
    tab1, tab2, tab3, tab4 = st.tabs(["üìä Summary Stats", "üìà Distributions", "üéØ Outlier Analysis", "üë• Group Analysis"])
    
    with tab1:
        st.markdown("#### Statistical Summary")
        
        # Custom descriptive statistics
        desc_stats = []
        for var in variables:
            stats_dict = {
                'Variable': var,
                'Mean': f"{df[var].mean():.2f}",
                'Median': f"{df[var].median():.2f}",
                'Mode': f"{df[var].mode().iloc[0]:.2f}",
                'Min': f"{df[var].min():.2f}",
                'Max': f"{df[var].max():.2f}",
                'Range': f"{df[var].max() - df[var].min():.2f}",
                'Std Dev': f"{df[var].std():.2f}"
            }
            desc_stats.append(stats_dict)
        
        desc_df = pd.DataFrame(desc_stats)
        st.dataframe(desc_df, use_container_width=True)
    
    with tab2:
        st.markdown("#### Age and Pregnancy Distributions")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Age distribution
            fig_age = px.histogram(df, x='Age', nbins=20, title='Age Distribution',
                                 color_discrete_sequence=['#1f77b4'])
            fig_age.update_layout(showlegend=False)
            st.plotly_chart(fig_age, use_container_width=True)
        
        with col2:
            # Pregnancy distribution
            pregnancy_counts = df['Pregnancies'].value_counts().sort_index()
            fig_preg = px.bar(x=pregnancy_counts.index, y=pregnancy_counts.values,
                            title='Pregnancies Distribution',
                            labels={'x': 'Number of Pregnancies', 'y': 'Count'},
                            color_discrete_sequence=['#ff7f0e'])
            st.plotly_chart(fig_preg, use_container_width=True)
        
        # Pregnancy categories
        st.markdown("#### Pregnancy Categories")
        preg_zero = (df['Pregnancies'] == 0).sum()
        preg_nonzero = (df['Pregnancies'] > 0).sum()
        
        col1, col2 = st.columns(2)
        with col1:
            plot_kpi("No Pregnancies", f"{preg_zero} ({preg_zero/len(df)*100:.1f}%)")
        with col2:
            plot_kpi("1+ Pregnancies", f"{preg_nonzero} ({preg_nonzero/len(df)*100:.1f}%)")
    
    with tab3:
        st.markdown("#### Outlier Detection")
        
        # Outlier analysis for each variable
        for var in variables:
            col1, col2 = st.columns([2, 1])
            
            with col1:
                # Box plot with outliers highlighted
                fig = go.Figure()
                fig.add_trace(go.Box(y=df[var], name=var, boxpoints='outliers'))
                fig.update_layout(title=f'{var} - Box Plot with Outliers', height=300)
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                # Outlier statistics
                outliers = detect_outliers_zscore(df[var])
                outlier_count = outliers.sum()
                outlier_pct = (outlier_count / len(df)) * 100
                
                st.markdown(f"**{var} Outliers:**")
                st.write(f"Count: {outlier_count}")
                st.write(f"Percentage: {outlier_pct:.1f}%")
                
                if outlier_count > 0:
                    outlier_values = df[var][outliers].values
                    st.write(f"Range: {outlier_values.min():.1f} - {outlier_values.max():.1f}")
    
    with tab4:
        st.markdown("#### Diabetes Rates by Groups")
        
        # Age groups analysis
        age_diabetes = df.groupby('AgeGroup')['Outcome'].agg(['count', 'sum', 'mean']).round(3)
        age_diabetes['percentage'] = (age_diabetes['mean'] * 100).round(1)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**Diabetes Rate by Age Group**")
            fig_age = px.bar(x=age_diabetes.index, y=age_diabetes['percentage'],
                           title='Diabetes Rate by Age Group (%)',
                           color=age_diabetes['percentage'],
                           color_continuous_scale='Reds')
            st.plotly_chart(fig_age, use_container_width=True)
        
        with col2:
            st.markdown("**Diabetes Rate by BMI Category**")
            bmi_diabetes = df.groupby('BMICategory')['Outcome'].agg(['count', 'sum', 'mean']).round(3)
            bmi_diabetes['percentage'] = (bmi_diabetes['mean'] * 100).round(1)
            
            fig_bmi = px.bar(x=bmi_diabetes.index, y=bmi_diabetes['percentage'],
                           title='Diabetes Rate by BMI Category (%)',
                           color=bmi_diabetes['percentage'],
                           color_continuous_scale='Blues')
            st.plotly_chart(fig_bmi, use_container_width=True)
        
        # Pregnancy groups analysis
        st.markdown("**Diabetes Rate by Pregnancy Groups**")
        preg_diabetes = df.groupby('PregnancyGroup')['Outcome'].agg(['count', 'sum', 'mean']).round(3)
        preg_diabetes['percentage'] = (preg_diabetes['mean'] * 100).round(1)
        
        fig_preg = px.bar(x=preg_diabetes.index, y=preg_diabetes['percentage'],
                        title='Diabetes Rate by Pregnancy Groups (%)',
                        color=preg_diabetes['percentage'],
                        color_continuous_scale='Greens')
        st.plotly_chart(fig_preg, use_container_width=True)

elif selected == "Inferential Analysis":
    st.header("üìä Inferential Statistics")
    
    # Create tabs for different statistical tests
    tab1, tab2, tab3, tab4 = st.tabs(["üß™ Hypothesis Tests", "üîó Correlation Analysis", "üìà ANOVA", "üéØ Chi-Square Tests"])
    
    with tab1:
        st.markdown("### üß™ Hypothesis Testing")
        
        # T-test for glucose levels
        st.markdown("#### T-Test: Glucose Levels by Diabetes Status")
        
        glucose_no_diabetes = df[df['Outcome'] == 0]['Glucose']
        glucose_diabetes = df[df['Outcome'] == 1]['Glucose']
        
        # Perform t-test
        t_stat, t_p_value = stats.ttest_ind(glucose_no_diabetes, glucose_diabetes)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("T-Statistic", f"{t_stat:.3f}")
        with col2:
            st.metric("P-Value", f"{t_p_value:.6f}")
        with col3:
            significance = "Significant" if t_p_value < 0.05 else "Not Significant"
            st.metric("Result", significance)
        
        # Visualize glucose distributions
        fig = go.Figure()
        fig.add_trace(go.Histogram(x=glucose_no_diabetes, name='No Diabetes', 
                                 opacity=0.7, nbinsx=30))
        fig.add_trace(go.Histogram(x=glucose_diabetes, name='Diabetes', 
                                 opacity=0.7, nbinsx=30))
        fig.update_layout(title='Glucose Distribution by Diabetes Status',
                         xaxis_title='Glucose Level', yaxis_title='Frequency',
                         barmode='overlay')
        st.plotly_chart(fig, use_container_width=True)
        
        # Mann-Whitney U test for pregnancies
        st.markdown("#### Mann-Whitney U Test: Pregnancies by Diabetes Status")
        
        preg_no_diabetes = df[df['Outcome'] == 0]['Pregnancies']
        preg_diabetes = df[df['Outcome'] == 1]['Pregnancies']
        
        u_stat, u_p_value = mannwhitneyu(preg_no_diabetes, preg_diabetes, alternative='two-sided')
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("U-Statistic", f"{u_stat:.0f}")
        with col2:
            st.metric("P-Value", f"{u_p_value:.6f}")
        with col3:
            significance = "Significant" if u_p_value < 0.05 else "Not Significant"
            st.metric("Result", significance)
    
    with tab2:
        st.markdown("### üîó Correlation Analysis")
        
        # Correlation matrix
        numeric_cols = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 
                       'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']
        corr_matrix = df[numeric_cols].corr()
        
        # Create interactive heatmap
        fig = px.imshow(corr_matrix, 
                       text_auto=True, 
                       aspect="auto",
                       title="Correlation Matrix Heatmap",
                       color_continuous_scale='RdBu_r')
        fig.update_layout(height=600)
        st.plotly_chart(fig, use_container_width=True)
        
        # Strongest correlations with Outcome
        st.markdown("#### Strongest Correlations with Diabetes Outcome")
        outcome_corr = corr_matrix['Outcome'].abs().sort_values(ascending=False)[1:]  # Exclude self-correlation
        
        corr_df = pd.DataFrame({
            'Variable': outcome_corr.index,
            'Correlation': corr_matrix['Outcome'][outcome_corr.index].round(3),
            'Absolute Correlation': outcome_corr.round(3)
        })
        st.dataframe(corr_df, use_container_width=True)
    
    with tab3:
        st.markdown("### üìà ANOVA Analysis")
        
        # ANOVA for glucose across age groups
        st.markdown("#### One-Way ANOVA: Glucose Levels Across Age Groups")
        
        age_groups = [df[df['AgeGroup'] == group]['Glucose'].values for group in df['AgeGroup'].unique()]
        f_stat, anova_p_value = f_oneway(*age_groups)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("F-Statistic", f"{f_stat:.3f}")
        with col2:
            st.metric("P-Value", f"{anova_p_value:.6f}")
        with col3:
            significance = "Significant" if anova_p_value < 0.05 else "Not Significant"
            st.metric("Result", significance)
        
        # Box plot for glucose by age groups
        fig = px.box(df, x='AgeGroup', y='Glucose', 
                    title='Glucose Distribution by Age Group',
                    color='AgeGroup')
        st.plotly_chart(fig, use_container_width=True)
        
        # Post-hoc analysis if significant
        if anova_p_value < 0.05:
            st.markdown("#### Post-Hoc Analysis (Tukey HSD)")
            from scipy.stats import tukey_hsd
            
            # Perform Tukey HSD test
            tukey_result = tukey_hsd(*age_groups)
            
            # Create pairwise comparison table
            age_group_names = df['AgeGroup'].unique()
            comparisons = []
            
            for i in range(len(age_group_names)):
                for j in range(i+1, len(age_group_names)):
                    p_val = tukey_result.pvalue[i, j]
                    comparisons.append({
                        'Group 1': age_group_names[i],
                        'Group 2': age_group_names[j],
                        'P-Value': f"{p_val:.4f}",
                        'Significant': "Yes" if p_val < 0.05 else "No"
                    })
            
            tukey_df = pd.DataFrame(comparisons)
            st.dataframe(tukey_df, use_container_width=True)
    
    with tab4:
        st.markdown("### üéØ Chi-Square Tests")
        
        # Chi-square test for Age Group vs Outcome
        st.markdown("#### Chi-Square Test: Age Group vs Diabetes Outcome")
        
        contingency_age = pd.crosstab(df['AgeGroup'], df['Outcome'])
        chi2_age, p_age, dof_age, expected_age = chi2_contingency(contingency_age)
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Chi-Square", f"{chi2_age:.3f}")
        with col2:
            st.metric("P-Value", f"{p_age:.6f}")
        with col3:
            st.metric("Degrees of Freedom", dof_age)
        with col4:
            significance = "Significant" if p_age < 0.05 else "Not Significant"
            st.metric("Result", significance)
        
        # Display contingency table
        st.markdown("**Contingency Table: Age Group vs Outcome**")
        st.dataframe(contingency_age, use_container_width=True)
        
        # Chi-square test for BMI Category vs Outcome
        st.markdown("#### Chi-Square Test: BMI Category vs Diabetes Outcome")
        
        contingency_bmi = pd.crosstab(df['BMICategory'], df['Outcome'])
        chi2_bmi, p_bmi, dof_bmi, expected_bmi = chi2_contingency(contingency_bmi)
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Chi-Square", f"{chi2_bmi:.3f}")
        with col2:
            st.metric("P-Value", f"{p_bmi:.6f}")
        with col3:
            st.metric("Degrees of Freedom", dof_bmi)
        with col4:
            significance = "Significant" if p_bmi < 0.05 else "Not Significant"
            st.metric("Result", significance)
        
        # Display contingency table
        st.markdown("**Contingency Table: BMI Category vs Outcome**")
        st.dataframe(contingency_bmi, use_container_width=True)

elif selected == "Models":
    st.header("ü§ñ Predictive Modeling")
    
    # Create tabs for different models
    tab1, tab2, tab3 = st.tabs(["üìà Linear Regression", "üéØ Logistic Regression", "üîÑ Interaction Effects"])
    
    with tab1:
        st.markdown("### üìà Multiple Linear Regression: Predicting Glucose Levels")
        
        # Prepare data for linear regression
        X_features = ['Age', 'BMI', 'Pregnancies', 'BloodPressure', 'SkinThickness', 'Insulin', 'DiabetesPedigreeFunction']
        X_linear = df[X_features].copy()
        y_glucose = df['Glucose'].copy()
        
        # Handle missing values (zeros in this dataset often represent missing values)
        X_linear_clean = X_linear.replace(0, np.nan)
        
        # Fill missing values with median
        for col in X_linear_clean.columns:
            if X_linear_clean[col].isnull().sum() > 0:
                X_linear_clean[col].fillna(X_linear_clean[col].median(), inplace=True)
        
        # Add constant for statsmodels
        X_linear_sm = sm.add_constant(X_linear_clean)
        
        # Fit the model
        linear_model = sm.OLS(y_glucose, X_linear_sm).fit()
        
        # Display model summary
        st.markdown("#### Model Summary")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("R-squared", f"{linear_model.rsquared:.4f}")
        with col2:
            st.metric("Adj. R-squared", f"{linear_model.rsquared_adj:.4f}")
        with col3:
            st.metric("F-statistic", f"{linear_model.fvalue:.2f}")
        with col4:
            st.metric("F p-value", f"{linear_model.f_pvalue:.6f}")
        
        # Coefficients table
        st.markdown("#### Model Coefficients")
        coeff_df = pd.DataFrame({
            'Variable': linear_model.params.index,
            'Coefficient': linear_model.params.values.round(4),
            'Std Error': linear_model.bse.values.round(4),
            'P-Value': linear_model.pvalues.values.round(6),
            'Significant': ['Yes' if p < 0.05 else 'No' for p in linear_model.pvalues.values]
        })
        st.dataframe(coeff_df, use_container_width=True)
        
        # Residual plots
        st.markdown("#### Residual Analysis")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Residuals vs Fitted
            residuals = linear_model.resid
            fitted = linear_model.fittedvalues
            
            fig = px.scatter(x=fitted, y=residuals, 
                           title='Residuals vs Fitted Values',
                           labels={'x': 'Fitted Values', 'y': 'Residuals'})
            fig.add_hline(y=0, line_dash="dash", line_color="red")
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # Q-Q plot
            from scipy.stats import probplot
            
            qq_data = probplot(residuals, dist="norm")
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=qq_data[0][0], y=qq_data[0][1], 
                                   mode='markers', name='Sample Quantiles'))
            fig.add_trace(go.Scatter(x=qq_data[0][0], y=qq_data[1][1] + qq_data[1][0] * qq_data[0][0],
                                   mode='lines', name='Theoretical Line', line=dict(color='red')))
            fig.update_layout(title='Q-Q Plot of Residuals', 
                            xaxis_title='Theoretical Quantiles',
                            yaxis_title='Sample Quantiles')
            st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        st.markdown("### üéØ Logistic Regression: Predicting Diabetes")
        
        # Prepare data for logistic regression
        X_log_features = ['BMI', 'Age', 'Glucose']
        X_logistic = df[X_log_features].copy()
        y_outcome = df['Outcome'].copy()
        
        # Fit logistic regression with statsmodels
        X_logistic_sm = sm.add_constant(X_logistic)
        logistic_model = sm.Logit(y_outcome, X_logistic_sm).fit()
        
        # Fit with sklearn for additional metrics
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X_logistic)
        sklearn_model = LogisticRegression(random_state=42)
        sklearn_model.fit(X_scaled, y_outcome)
        
        # Predictions
        y_pred = sklearn_model.predict(X_scaled)
        y_pred_proba = sklearn_model.predict_proba(X_scaled)[:, 1]
        
        # Model performance metrics
        st.markdown("#### Model Performance")
        
        accuracy = accuracy_score(y_outcome, y_pred)
        sensitivity = recall_score(y_outcome, y_pred)
        specificity = recall_score(y_outcome, y_pred, pos_label=0)
        precision = precision_score(y_outcome, y_pred)
        auc_score = roc_auc_score(y_outcome, y_pred_proba)
        
        col1, col2, col3, col4, col5 = st.columns(5)
        with col1:
            st.metric("Accuracy", f"{accuracy:.3f}")
        with col2:
            st.metric("Sensitivity", f"{sensitivity:.3f}")
        with col3:
            st.metric("Specificity", f"{specificity:.3f}")
        with col4:
            st.metric("Precision", f"{precision:.3f}")
        with col5:
            st.metric("AUC", f"{auc_score:.3f}")
        
        # Confusion Matrix
        st.markdown("#### Confusion Matrix")
        cm = confusion_matrix(y_outcome, y_pred)
        
        fig = px.imshow(cm, text_auto=True, aspect="auto",
                       title="Confusion Matrix",
                       labels=dict(x="Predicted", y="Actual"),
                       x=['No Diabetes', 'Diabetes'],
                       y=['No Diabetes', 'Diabetes'])
        st.plotly_chart(fig, use_container_width=True)
        
        # ROC Curve
        st.markdown("#### ROC Curve")
        fpr, tpr, _ = roc_curve(y_outcome, y_pred_proba)
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', 
                               name=f'ROC Curve (AUC = {auc_score:.3f})'))
        fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', 
                               name='Random Classifier', line=dict(dash='dash')))
        fig.update_layout(title='ROC Curve',
                         xaxis_title='False Positive Rate',
                         yaxis_title='True Positive Rate')
        st.plotly_chart(fig, use_container_width=True)
        
        # Hosmer-Lemeshow Test
        st.markdown("#### Hosmer-Lemeshow Goodness of Fit Test")
        hl_stat, hl_p_value = hosmer_lemeshow_test(y_outcome, y_pred_proba)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("HL Statistic", f"{hl_stat:.3f}")
        with col2:
            st.metric("P-Value", f"{hl_p_value:.4f}")
        with col3:
            fit_quality = "Good Fit" if hl_p_value > 0.05 else "Poor Fit"
            st.metric("Model Fit", fit_quality)
        
        # Odds Ratios
        st.markdown("#### Odds Ratios")
        odds_ratios = np.exp(logistic_model.params[1:])  # Exclude intercept
        or_df = pd.DataFrame({
            'Variable': X_log_features,
            'Odds Ratio': odds_ratios.round(3),
            'Lower CI': np.exp(logistic_model.conf_int().iloc[1:, 0]).round(3),
            'Upper CI': np.exp(logistic_model.conf_int().iloc[1:, 1]).round(3),
            'P-Value': logistic_model.pvalues[1:].round(6)
        })
        st.dataframe(or_df, use_container_width=True)
    
    with tab3:
        st.markdown("### üîÑ Interaction Effects Analysis")
        
        # Model 1: Main effects only
        st.markdown("#### Model Comparison: Main Effects vs Interaction Effects")
        
        X_main = df[['BMI', 'Age', 'Glucose', 'Pregnancies']].copy()
        
        # Model 1: Main effects
        X_main_sm = sm.add_constant(X_main)
        model1 = sm.Logit(y_outcome, X_main_sm).fit()
        
        # Model 2: With BMI √ó Age interaction
        X_interaction = X_main.copy()
        X_interaction['BMI_Age_Interaction'] = X_interaction['BMI'] * X_interaction['Age']
        X_interaction_sm = sm.add_constant(X_interaction)
        model2 = sm.Logit(y_outcome, X_interaction_sm).fit()
        
        # Likelihood Ratio Test
        lr_stat = 2 * (model2.llf - model1.llf)
        lr_p_value = 1 - stats.chi2.cdf(lr_stat, df=1)
        
        st.markdown("#### Likelihood Ratio Test Results")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("LR Statistic", f"{lr_stat:.3f}")
        with col2:
            st.metric("P-Value", f"{lr_p_value:.4f}")
        with col3:
            interaction_significant = "Significant" if lr_p_value < 0.05 else "Not Significant"
            st.metric("Interaction Effect", interaction_significant)
        
        # Model comparison table
        st.markdown("#### Model Comparison")
        
        comparison_df = pd.DataFrame({
            'Model': ['Model 1 (Main Effects)', 'Model 2 (With Interaction)'],
            'Log-Likelihood': [model1.llf, model2.llf],
            'AIC': [model1.aic, model2.aic],
            'BIC': [model1.bic, model2.bic],
            'Pseudo R¬≤': [model1.prsquared, model2.prsquared]
        })
        st.dataframe(comparison_df.round(4), use_container_width=True)
        
        # Display coefficients for both models
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**Model 1 Coefficients**")
            model1_coeff = pd.DataFrame({
                'Variable': model1.params.index,
                'Coefficient': model1.params.values.round(4),
                'P-Value': model1.pvalues.values.round(6)
            })
            st.dataframe(model1_coeff, use_container_width=True)
        
        with col2:
            st.markdown("**Model 2 Coefficients**")
            model2_coeff = pd.DataFrame({
                'Variable': model2.params.index,
                'Coefficient': model2.params.values.round(4),
                'P-Value': model2.pvalues.values.round(6)
            })
            st.dataframe(model2_coeff, use_container_width=True)
        
        # Odds ratios for significant predictors
        if lr_p_value < 0.05:
            st.markdown("#### Odds Ratios (Model with Interaction)")
            
            odds_ratios_int = np.exp(model2.params[1:])  # Exclude intercept
            or_int_df = pd.DataFrame({
                'Variable': model2.params.index[1:],
                'Odds Ratio': odds_ratios_int.round(3),
                'P-Value': model2.pvalues[1:].round(6),
                'Significant': ['Yes' if p < 0.05 else 'No' for p in model2.pvalues[1:]]
            })
            st.dataframe(or_int_df, use_container_width=True)

elif selected == "Conclusions":
    st.header("‚úÖ Conclusions & Recommendations")
    
    # Summary of key findings
    st.markdown("### üîç Key Statistical Findings")
    
    # Calculate key statistics for conclusions
    diabetes_rate = df['Outcome'].mean() * 100
    high_glucose_diabetes = df[df['Glucose'] > 140]['Outcome'].mean() * 100
    obese_diabetes = df[df['BMICategory'] == 'Obese']['Outcome'].mean() * 100
    older_diabetes = df[df['AgeGroup'] == '50+']['Outcome'].mean() * 100
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        #### üìä Population Characteristics
        
        - **Overall diabetes prevalence**: {:.1f}% in this Pima Indian population
        - **Age distribution**: Ranges from 21 to 81 years (mean: {:.1f} years)
        - **BMI patterns**: {:.1f}% are obese (BMI ‚â•30)
        - **Pregnancy history**: {:.1f}% have had no pregnancies
        """.format(
            diabetes_rate,
            df['Age'].mean(),
            (df['BMICategory'] == 'Obese').mean() * 100,
            (df['Pregnancies'] == 0).mean() * 100
        ))
    
    with col2:
        st.markdown("""
        #### üéØ High-Risk Groups
        
        - **High glucose (>140 mg/dL)**: {:.1f}% diabetes rate
        - **Obese individuals**: {:.1f}% diabetes rate  
        - **Age 50+ group**: {:.1f}% diabetes rate
        - **Multiple pregnancies**: Higher diabetes risk observed
        """.format(
            high_glucose_diabetes,
            obese_diabetes,
            older_diabetes
        ))
    
    # Risk factors analysis
    st.markdown("### ‚ö†Ô∏è Primary Risk Factors")
    
    # Create risk factor importance chart
    risk_factors = {
        'Glucose Level': 0.47,  # Based on typical correlation
        'BMI': 0.29,
        'Age': 0.24,
        'Pregnancies': 0.22,
        'Blood Pressure': 0.15,
        'Diabetes Pedigree': 0.17
    }
    
    fig = px.bar(x=list(risk_factors.keys()), y=list(risk_factors.values()),
                title='Relative Importance of Risk Factors',
                labels={'x': 'Risk Factors', 'y': 'Correlation with Diabetes'},
                color=list(risk_factors.values()),
                color_continuous_scale='Reds')
    st.plotly_chart(fig, use_container_width=True)
    
    # Clinical recommendations
    st.markdown("### üè• Clinical Recommendations")
    
    tab1, tab2, tab3 = st.tabs(["üéØ Prevention Strategies", "üìã Screening Guidelines", "üíä Management Approaches"])
    
    with tab1:
        st.markdown("""
        #### Primary Prevention Strategies
        
        **High-Priority Interventions:**
        
        1. **Glucose Management**
           - Regular glucose monitoring for individuals with levels >100 mg/dL
           - Dietary counseling focusing on carbohydrate control
           - Physical activity programs (150+ minutes/week moderate exercise)
        
        2. **Weight Management**
           - Target BMI <25 kg/m¬≤ for optimal diabetes prevention
           - Structured weight loss programs for obese individuals (BMI ‚â•30)
           - Nutritional counseling with registered dietitians
        
        3. **Age-Specific Interventions**
           - Enhanced screening for women >40 years
           - Lifestyle modification programs tailored to older adults
           - Regular health assessments every 6-12 months
        """)
    
    with tab2:
        st.markdown("""
        #### Evidence-Based Screening Guidelines
        
        **Recommended Screening Frequency:**
        
        - **Annual screening** for:
          - Women with BMI ‚â•30 kg/m¬≤
          - Age ‚â•45 years
          - Previous gestational diabetes
          - Multiple pregnancy history (‚â•3)
        
        - **Biannual screening** for:
          - BMI 25-29.9 kg/m¬≤ with additional risk factors
          - Family history of diabetes
          - Glucose levels 100-125 mg/dL (prediabetes range)
        
        **Screening Methods:**
        - Fasting plasma glucose (preferred)
        - Oral glucose tolerance test (OGTT)
        - HbA1c testing for long-term glucose control assessment
        """)
    
    with tab3:
        st.markdown("""
        #### Diabetes Management Approaches
        
        **For Diagnosed Patients:**
        
        1. **Glucose Control Targets**
           - HbA1c <7% for most adults
           - Individualized targets based on age and comorbidities
           - Regular monitoring and medication adjustments
        
        2. **Lifestyle Modifications**
           - Medical nutrition therapy
           - Regular physical activity (aerobic + resistance training)
           - Weight management support
           - Smoking cessation programs
        
        3. **Complication Prevention**
           - Annual eye examinations
           - Kidney function monitoring
           - Cardiovascular risk assessment
           - Foot care education and regular examinations
        """)
    
    # Statistical model insights
    st.markdown("### üìà Predictive Model Insights")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        #### Linear Regression (Glucose Prediction)
        
        - **Key predictors** of glucose levels identified
        - **Age and BMI** show strongest associations
        - Model explains significant variance in glucose levels
        - Useful for identifying individuals at risk of hyperglycemia
        """)
    
    with col2:
        st.markdown("""
        #### Logistic Regression (Diabetes Prediction)
        
        - **High accuracy** in diabetes prediction (>75%)
        - **Glucose, BMI, and Age** are primary predictors
        - Model demonstrates good discriminative ability (AUC >0.8)
        - Suitable for clinical decision support systems
        """)
    
    # Implementation recommendations
    st.markdown("### üöÄ Implementation Recommendations")
    
    st.info("""
    **For Healthcare Providers:**
    
    1. **Risk Stratification**: Use the predictive models to identify high-risk patients
    2. **Targeted Interventions**: Focus resources on individuals with multiple risk factors
    3. **Regular Monitoring**: Implement systematic follow-up for at-risk populations
    4. **Community Programs**: Develop culturally appropriate diabetes prevention programs
    
    **For Public Health Policy:**
    
    1. **Population Screening**: Implement community-wide screening programs
    2. **Health Education**: Develop targeted educational campaigns about diabetes risk factors
    3. **Healthcare Access**: Ensure accessible diabetes care services in high-risk communities
    4. **Research Investment**: Continue longitudinal studies to refine risk prediction models
    """)
    
    # Final summary
    st.markdown("### üéØ Executive Summary")
    
    st.success("""
    **Key Takeaways:**
    
    ‚úÖ **Diabetes affects 1 in 3 women** in this Pima Indian population
    
    ‚úÖ **Glucose level is the strongest predictor** - levels >140 mg/dL indicate very high risk
    
    ‚úÖ **Obesity significantly increases risk** - BMI ‚â•30 doubles diabetes likelihood
    
    ‚úÖ **Age matters** - risk increases substantially after age 40
    
    ‚úÖ **Multiple risk factors compound** - individuals with high BMI + age + glucose have >80% diabetes risk
    
    ‚úÖ **Prevention is possible** - lifestyle interventions can significantly reduce diabetes incidence
    
    ‚úÖ **Early detection saves lives** - regular screening enables timely intervention
    """)
    
    # Add some visual flair
    st.balloons()
